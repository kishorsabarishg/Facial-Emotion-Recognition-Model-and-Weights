{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "CKPLUSFER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kishorsabarishg/Facial-Emotion-Recognition-Model-and-Weights/blob/master/CKPLUSFER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGpaPTm_EF09",
        "colab_type": "text"
      },
      "source": [
        "## **Emotion Recognition on CK+45 Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifytgge0CUCd",
        "colab_type": "text"
      },
      "source": [
        "# Importing Pre-processing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxha_cCTNcMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PRkF_fYCaPq",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Google Drive to load the dataste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg68hl31NjFx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "80fa4bbb-3a14-4b08-95e6-6c2e5f9d831c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vowF5uFDCftQ",
        "colab_type": "text"
      },
      "source": [
        "# Import the layers of the Network and the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFe3uRxoNcMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c9a2e13-eb9c-4e05-ffb5-d28608b6544c"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Input, Activation, Dropout\n",
        "from keras.models import Model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njLa0pXLCmI3",
        "colab_type": "text"
      },
      "source": [
        "# Extracting the dataste zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYz1QGTlNxJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42fbc34e-1578-4642-940d-3a5e9e734d81"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/images.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSe7KjI-CrO8",
        "colab_type": "text"
      },
      "source": [
        "# Locating the path of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptUa8L5MO6AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir = \"/content/\"\n",
        "image_dir = os.path.join(base_dir,\"images\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqCFQms8C7Vl",
        "colab_type": "text"
      },
      "source": [
        "# Initializing Input and Targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMtARK2pNcMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "current_id = 0\n",
        "label_ids = {}\n",
        "Y = []"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV2UOTneC_d4",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRCw4837NcMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for root,dirs,files in os.walk(image_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
        "            path = os.path.join(root, file)\n",
        "            label = os.path.basename(root).replace(\" \",\"-\").lower()\n",
        "            #print(label,path)\n",
        "            if not label in label_ids:\n",
        "                label_ids[label] = current_id\n",
        "                current_id += 1\n",
        "            id_ = label_ids[label]\n",
        "            #print(label_ids)\n",
        "            #X_train.append(path)\n",
        "            #y_train.append(label)\n",
        "            pil_image = Image.open(path).convert(\"L\")#convert image into numbers we are using PIL and \"L\" is ussed for grayscale\n",
        "            size = (128,128)\n",
        "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
        "            image_array = np.array(final_image, \"uint8\")\n",
        "            X.append(image_array)\n",
        "            Y.append(id_)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wadxx7M6DGpH",
        "colab_type": "text"
      },
      "source": [
        "# Converting List into an Numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yueA-EoVNcMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.asarray(X)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0MFfjc8NcMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1 = X.shape[1]\n",
        "l2 = X.shape[2]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcRCF26mNcMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.reshape(-1,l1,l2,1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCpcMsNCNcMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8e02cfce-be2c-4e3b-8eb4-c9d72cb1254d"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(981, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6bvLuo6DKpb",
        "colab_type": "text"
      },
      "source": [
        "# Normalizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQRChI4NNcM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X/255"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXS2a5ZbNcM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(X[1])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9cUa60yNcM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(Y)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axUjvCJGDRgv",
        "colab_type": "text"
      },
      "source": [
        "# Creating Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncF9YPRgNcM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EMJECLANcNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, shuffle = True, random_state = 42)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BO3J5kGDUYi",
        "colab_type": "text"
      },
      "source": [
        "# Functional API of KERAS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MhRW-nyNcND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Emotion_Recognition(input_shape):\n",
        "    \n",
        "    X_input = Input(input_shape)\n",
        "    \n",
        "    X = Conv2D(128,(5,5), activation = 'relu')(X_input)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    X = Conv2D(128,(5,5), activation = 'relu')(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    X = MaxPooling2D(2,2)(X)\n",
        "    \n",
        "    X = Conv2D(64,(3,3), activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    X = Conv2D(64,(3,3), activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    X = MaxPooling2D(2,2)(X)\n",
        "       \n",
        "    X = Conv2D(32,(3,3), activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    X = Conv2D(32,(3,3), activation = \"relu\")(X)\n",
        "    X = BatchNormalization()(X)\n",
        "    X = Activation(\"relu\")(X)\n",
        "    \n",
        "    X = MaxPooling2D(2,2)(X)\n",
        "    \n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    X = Dense(512, activation = \"relu\")(X)\n",
        "    X = Dense(7, activation = \"softmax\")(X)\n",
        "    \n",
        "    model = Model(inputs = X_input, outputs = X, name = \"EMOTION_RECOGNIZER\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABOVOG9nDXfL",
        "colab_type": "text"
      },
      "source": [
        "# Function Call"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4iARvT4NcNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emo_rec = Emotion_Recognition(X.shape[1:])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfk-9U1pDZgg",
        "colab_type": "text"
      },
      "source": [
        "# Compiling Model. Optimizer is ADAM, Loss is Sparse Categorical Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL8ZxZ8GNcNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = emo_rec.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiMex8_aDiPx",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzeZir4bNcNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "178167e2-db88-457f-c966-ab2b87b9bbd1"
      },
      "source": [
        "emo_rec.fit(X_train, Y_train, epochs = 50, batch_size = 32, validation_split = 0.2, shuffle = True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 627 samples, validate on 157 samples\n",
            "Epoch 1/50\n",
            "627/627 [==============================] - 24s 39ms/step - loss: 4.1677 - accuracy: 0.5024 - val_loss: 3.7174 - val_accuracy: 0.0510\n",
            "Epoch 2/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.4994 - accuracy: 0.8278 - val_loss: 1.9514 - val_accuracy: 0.0573\n",
            "Epoch 3/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.1690 - accuracy: 0.9585 - val_loss: 1.9552 - val_accuracy: 0.0573\n",
            "Epoch 4/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0670 - accuracy: 0.9872 - val_loss: 1.9586 - val_accuracy: 0.0573\n",
            "Epoch 5/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0302 - accuracy: 0.9936 - val_loss: 1.9589 - val_accuracy: 0.0573\n",
            "Epoch 6/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.0573\n",
            "Epoch 7/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.0573\n",
            "Epoch 8/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.9595 - val_accuracy: 0.0573\n",
            "Epoch 9/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.9594 - val_accuracy: 0.0573\n",
            "Epoch 10/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.9595 - val_accuracy: 0.0573\n",
            "Epoch 11/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9595 - val_accuracy: 0.0573\n",
            "Epoch 12/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9595 - val_accuracy: 0.0573\n",
            "Epoch 13/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 7.3924e-04 - accuracy: 1.0000 - val_loss: 1.9595 - val_accuracy: 0.0573\n",
            "Epoch 14/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 6.2584e-04 - accuracy: 1.0000 - val_loss: 1.9596 - val_accuracy: 0.0573\n",
            "Epoch 15/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.8096e-04 - accuracy: 1.0000 - val_loss: 1.9598 - val_accuracy: 0.0573\n",
            "Epoch 16/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.7405e-04 - accuracy: 1.0000 - val_loss: 1.9602 - val_accuracy: 0.0573\n",
            "Epoch 17/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.4321e-04 - accuracy: 1.0000 - val_loss: 1.9616 - val_accuracy: 0.0573\n",
            "Epoch 18/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 4.2752e-04 - accuracy: 1.0000 - val_loss: 1.9644 - val_accuracy: 0.0573\n",
            "Epoch 19/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 3.5872e-04 - accuracy: 1.0000 - val_loss: 1.9669 - val_accuracy: 0.0573\n",
            "Epoch 20/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 4.1340e-04 - accuracy: 1.0000 - val_loss: 1.9700 - val_accuracy: 0.0892\n",
            "Epoch 21/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 2.8465e-04 - accuracy: 1.0000 - val_loss: 1.9729 - val_accuracy: 0.1274\n",
            "Epoch 22/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 2.5898e-04 - accuracy: 1.0000 - val_loss: 1.9687 - val_accuracy: 0.1529\n",
            "Epoch 23/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 2.5510e-04 - accuracy: 1.0000 - val_loss: 1.9526 - val_accuracy: 0.2038\n",
            "Epoch 24/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 2.6837e-04 - accuracy: 1.0000 - val_loss: 1.9041 - val_accuracy: 0.2548\n",
            "Epoch 25/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 2.2050e-04 - accuracy: 1.0000 - val_loss: 1.8303 - val_accuracy: 0.2739\n",
            "Epoch 26/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.6416e-04 - accuracy: 1.0000 - val_loss: 1.7010 - val_accuracy: 0.3057\n",
            "Epoch 27/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.8482e-04 - accuracy: 1.0000 - val_loss: 1.5252 - val_accuracy: 0.3822\n",
            "Epoch 28/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.6071e-04 - accuracy: 1.0000 - val_loss: 1.3090 - val_accuracy: 0.4841\n",
            "Epoch 29/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.3315e-04 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.6115\n",
            "Epoch 30/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.0819e-04 - accuracy: 1.0000 - val_loss: 0.8135 - val_accuracy: 0.6561\n",
            "Epoch 31/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.0707e-04 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.7580\n",
            "Epoch 32/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.0800e-04 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.8599\n",
            "Epoch 33/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 9.5546e-05 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8981\n",
            "Epoch 34/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 8.5610e-05 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9299\n",
            "Epoch 35/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 8.1317e-05 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9554\n",
            "Epoch 36/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 2.0727e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9682\n",
            "Epoch 37/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 1.0804e-04 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9682\n",
            "Epoch 38/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 7.6981e-05 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9682\n",
            "Epoch 39/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 7.4918e-05 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9745\n",
            "Epoch 40/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 6.3162e-05 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9745\n",
            "Epoch 41/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 6.1152e-05 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9682\n",
            "Epoch 42/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.7189e-05 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9682\n",
            "Epoch 43/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.2251e-05 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9682\n",
            "Epoch 44/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.1961e-05 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9682\n",
            "Epoch 45/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 5.0383e-05 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9682\n",
            "Epoch 46/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 3.7867e-05 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9682\n",
            "Epoch 47/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 4.2194e-05 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9682\n",
            "Epoch 48/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 4.1499e-05 - accuracy: 1.0000 - val_loss: 0.0825 - val_accuracy: 0.9745\n",
            "Epoch 49/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 3.9519e-05 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9745\n",
            "Epoch 50/50\n",
            "627/627 [==============================] - 11s 18ms/step - loss: 3.2131e-05 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f554ef2bf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUrUhWScDpIB",
        "colab_type": "text"
      },
      "source": [
        "# Predicting on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6jw04KTNcNN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2ca40a98-a0d9-4ea1-86c4-06f793c14b3d"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "pred = np.zeros((7,1))\n",
        "pred = [[0],[1],[2],[3],[4],[5],[6]]\n",
        "preds = emo_rec.evaluate(X_test, Y_test)\n",
        "Y_pred = emo_rec.predict(X_test, batch_size=32, verbose=0)\n",
        "print(Y_pred.shape)\n",
        "predictions1 = np.dot(Y_pred,pred)\n",
        "print(predictions1.shape)\n",
        "predictions1 = np.array(predictions1, dtype = int)\n",
        "predict1 = np.ndarray.flatten(predictions1)\n",
        "print(predict1.shape)\n",
        "conf_mat = confusion_matrix(Y_test, predict1)\n",
        "print(predictions1[-1])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_mat)\n",
        "print(\"Test Loss:\", preds[0])\n",
        "print(\"Test Accuracy:\", preds[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "197/197 [==============================] - 1s 7ms/step\n",
            "(197, 7)\n",
            "(197, 1)\n",
            "(197,)\n",
            "[2]\n",
            "Confusion Matrix:\n",
            "[[34  0  0  0  0  0  0]\n",
            " [ 9 35  0  0  0  0  0]\n",
            " [ 0 11 16  0  0  0  0]\n",
            " [ 0  0  4  7  0  0  0]\n",
            " [ 0  0  0 16  3  0  0]\n",
            " [ 0  0  0  0 25 25  0]\n",
            " [ 0  0  0  0  0 12  0]]\n",
            "Test Loss: 0.06884629828240817\n",
            "Test Accuracy: 0.9796954393386841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGP4-qmnDsqx",
        "colab_type": "text"
      },
      "source": [
        "# Storing the Model, Weights and Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDwOSYijNcNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file = emo_rec.to_json()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSfOoTnLNcNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"Emotion.json\", \"w\") as file:\n",
        "    file.write(json_file)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spam7PLlNcNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emo_rec.save_weights(\"Emotion_h5_file.h5\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTGAn5zNcNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "with open(\"lables.pickle\", \"wb\") as f:\n",
        "    pickle.dump(label_ids, f)"
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}